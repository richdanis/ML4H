{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d1cc00b",
   "metadata": {},
   "source": [
    "### Part 2: NLP learning based methods\n",
    "#### VADER\n",
    "##### Q1: Briefly explaining how this method works\n",
    "\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a freely available python package used as a lexicon and rule-based sentiment analysis tool. It is often used in context of social media based data like tweets in order to analyze a piece of text whether word/ statements made have a positive, negative or neutral sentiment. \n",
    "\n",
    "The VADER lexicon consists of a list of words and phrases which got sentiment ratings from 10 independent human raters who provided sentiment scores for over 9‚Äô000 token features in a range of -4 (extremely negative) to 4 (extremely positive). In this case, quality control of the ratings was ensured by keeping only lexical features which had a non-zero mean rating and standard deviations less than 2.5. As a result, VADER has a list of over 7‚Äô500 lexical token features with scores which both indicate positive or negative valence (score>0 or score<0) and the sentiment intensity of before mentioned range. For example, the word ‚Äúgood‚Äù has positive valence and an sentiment intensity score of 1.9.\n",
    "\n",
    "In particular, VADER makes raw categorizations of words into positive, negative or neutral categories. When giving a sentence as input, VADER gives scores to these categories based on their ratios for proportions of text that fall in each category. As a result, the positive, negative and neutral categories should add up to 1. \n",
    "\n",
    "Moreover, it is important to mention that these proportions are just raw categorizations by the lexicon of each word presented in the text. These categorizations do not include the VADER rule-based enhancements such as degree modifiers, worder-order sensitivity for sentiment-laden multi-word phrases, word-shape amplifiers etc. as we will describe later. \n",
    "\n",
    "These rule-based enhancements are expressed in the compound score as described in the following.\n",
    "\n",
    "In order to evaluate the sentiment of whole sentences, the compound score is computed using the sum of the valence score, adjusted according to the valence rules (e.g.: word-order sensitivity), of each word in the sentence and then normalize this sum to become a value between -1 (very negative sentiment) and +1 (very positive sentiment). Using this technique, one obtains a useful unidimensional score between -1 and +1 to evaluate the overall sentiment of whole sentences.\n",
    "In the following the authors provided recommended thresholds for the interpretation of the compound score:\n",
    "\n",
    "1. positive sentiment: compound score >= 0.05\n",
    "2. neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n",
    "3. negative sentiment: compound score <= -0.05\n",
    "\n",
    "Furthermore, we would like to give examples of typical use cases/valence rules for sentiment analysis and the types of text VADER can deal with:\n",
    "\n",
    "    -\tTypical negotiations (e.g.: ‚Äúnot good‚Äù)\n",
    "    -\tContractions of negations (e.g.: ‚Äúwasn‚Äôt very good‚Äù)\n",
    "    -\tUse of punctuation to show increased sentiment intensity (e.g.: ‚ÄùGood!!!!!!‚Äù)\n",
    "    -\tUse of word-shape (e.g.: ‚ÄúBAAAAAD‚Äù -> CAPS for words/phrases)\n",
    "    -\tDegree modifiers to alter sentiment intensity (e.g.: intensity boosters like ‚Äúvery‚Äù or dampeners like ‚Äúkind of‚Äù)\n",
    "    -\tSentiment-laden slangs (e.g.: ‚Äúsux‚Äù)\n",
    "    -\tSentiment-laden emoticons (e.g.: ‚Äú:)‚Äù or ‚Äú:D‚Äù)\n",
    "    -\tUtf-8 encoded emojis \n",
    "    -\tInitialisms and Acronyms (e.g.: ‚Äúlol‚Äù)\n",
    "\n",
    "As a last remark one can point out that VADER works in conjunction with NLTK as well such that VADER can do sentiment analysis on longer texts like for example decomposing paragraphs/articles etc. into sentence-level analyses.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a14752cc",
   "metadata": {},
   "source": [
    "##### Q2: Provide a code snippet detailing how to use it for our task\n",
    "\n",
    "In light of what you have learned about this method, reflect on pre-processing steps that might be\n",
    "unnecessary when using VADER .\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfa7c84e",
   "metadata": {},
   "source": [
    "###### Installing VADER package \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "440abb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: vaderSentiment in /home/chris/.local/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /home/chris/.local/lib/python3.8/site-packages (from vaderSentiment) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->vaderSentiment) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chris/.local/lib/python3.8/site-packages (from requests->vaderSentiment) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->vaderSentiment) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->vaderSentiment) (1.25.8)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install vaderSentiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6367fa1",
   "metadata": {},
   "source": [
    "###### Importing the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ce8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0b183dd",
   "metadata": {},
   "source": [
    "###### Analyzing dummy example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2947e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.482, 'pos': 0.518, 'compound': 0.8619}\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "text = \"I love the course Machine Learning for Healthcare! It's amazing!\"\n",
    "\n",
    "scores = analyzer.polarity_scores(text)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0eeae48",
   "metadata": {},
   "source": [
    "As one can see, VADER is capable to process whole sentences by applying parts of our pre-processing steps like tokenization which seems to be not necessary anymore. \n",
    "\n",
    "Additionally, the overall sentence has a compound score of 0.8619 which means that the sentence has positive valence and a very high positive sentiment intensity (max.: 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2d220f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7662/3326796030.py:3: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = pd.read_csv('Data/TweetsCOV19.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# loading raw data and pre-processed/cleaned data\n",
    "raw_data = pd.read_csv('Data/TweetsCOV19.csv')\n",
    "cleaned_data = pd.read_csv('Data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d8f0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw texts\n",
      "0    From my blog: Californians support vaccine law...\n",
      "1    Secretary of State should recall Stormont next...\n",
      "2    While serving in Afghanistan in 2010, Marine C...\n",
      "3    witch vixen season starts tomorrow. you all sh...\n",
      "4    CGTN on the scene: \\n\\nAround 15,000 troops, 3...\n",
      "5    Looking like it may be a fall-like weekend com...\n",
      "6    i stopped caring what niggas think when i real...\n",
      "7    #LIVE: Chaos expected on Oct 1 across Hong Kon...\n",
      "8    I hold @kie_vs_theworld personally responsible...\n",
      "9                                @FuckITripped Exactly\n",
      "Name: TweetText, dtype: object\n",
      "---------------------\n",
      "clean texts\n",
      "0    from my blog californian support vaccine law ‚Äì...\n",
      "1    secretary of state should recall stormont next...\n",
      "2    while serving in afghanistan in 2010 marine co...\n",
      "3    witch vixen season start tomorrow you all shou...\n",
      "4    cgtn on the scene around 15000 troop 32 equipm...\n",
      "5    looking like it may be a falllike weekend comi...\n",
      "6    i stopped caring what nigga think when i reali...\n",
      "7    live chaos expected on oct 1 across hong kong ...\n",
      "8    i hold kievstheworld personally responsible fo...\n",
      "9                                 fuckitripped exactly\n",
      "Name: TweetText, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#loading 10 sample Tweets\n",
    "\n",
    "texts = raw_data['TweetText'][:10]\n",
    "texts_cleaned = cleaned_data['TweetText'][:10]\n",
    "\n",
    "\n",
    "print('raw texts')\n",
    "print(texts)\n",
    "print('---------------------')\n",
    "print('clean texts')\n",
    "print(texts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6dda09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From my blog: Californians support vaccine laws ‚Äì new poll diminishes anti-vaxxer power https://t.co/d5BaAda3ki {'neg': 0.0, 'neu': 0.828, 'pos': 0.172, 'compound': 0.4019}\n",
      "Secretary of State should recall Stormont next Monday at 10am.\n",
      "Those MLA‚Äôs who refuse to turn up (Whatever Party) s‚Ä¶ https://t.co/ZdArVTrKar {'neg': 0.092, 'neu': 0.795, 'pos': 0.113, 'compound': 0.128}\n",
      "While serving in Afghanistan in 2010, Marine Corporal Brandon Rumbaug was carrying a fellow Marine to safety when h‚Ä¶ https://t.co/Dipa5CbN1A {'neg': 0.0, 'neu': 0.872, 'pos': 0.128, 'compound': 0.4215}\n",
      "witch vixen season starts tomorrow. you all should be receiving the spell that turns you into your witchsona at mid‚Ä¶ https://t.co/ruYcgfoSdI {'neg': 0.111, 'neu': 0.889, 'pos': 0.0, 'compound': -0.3612}\n",
      "CGTN on the scene: \n",
      "\n",
      "Around 15,000 troops, 32 equipment units and 12 air formations composed of over 160 aircraft a‚Ä¶ https://t.co/btVQ5kDgAQ {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Looking like it may be a fall-like weekend coming up! Dry cold front looks to move through the area Friday with hig‚Ä¶ https://t.co/qOyZm9sS2B {'neg': 0.0, 'neu': 0.887, 'pos': 0.113, 'compound': 0.4199}\n",
      "i stopped caring what niggas think when i realized they will believe anything the next nigga tell them. {'neg': 0.191, 'neu': 0.667, 'pos': 0.142, 'compound': -0.0258}\n",
      "#LIVE: Chaos expected on Oct 1 across Hong Kong as anti-government protesters aim to spoil China's partyl. Follow o‚Ä¶ https://t.co/RQH5WoQ3PG {'neg': 0.237, 'neu': 0.763, 'pos': 0.0, 'compound': -0.6808}\n",
      "I hold @kie_vs_theworld personally responsible for what just happened ü§∑üèæ‚Äç‚ôÇÔ∏èüòÇ #RAW {'neg': 0.07, 'neu': 0.704, 'pos': 0.226, 'compound': 0.6369}\n",
      "@FuckITripped Exactly-------------------------------------------- {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "for text in texts: \n",
    "    score = analyzer.polarity_scores(text)\n",
    "    print(\"{:-<65} {}\".format(text, str(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa7111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from my blog californian support vaccine law ‚Äì new poll diminishes antivaxxer power {'neg': 0.0, 'neu': 0.816, 'pos': 0.184, 'compound': 0.4019}\n",
      "secretary of state should recall stormont next monday at 10am those mla ‚Äô s who refuse to turn up whatever party s ‚Ä¶ {'neg': 0.085, 'neu': 0.811, 'pos': 0.104, 'compound': 0.128}\n",
      "while serving in afghanistan in 2010 marine corporal brandon rumbaug wa carrying a fellow marine to safety when h ‚Ä¶ {'neg': 0.0, 'neu': 0.872, 'pos': 0.128, 'compound': 0.4215}\n",
      "witch vixen season start tomorrow you all should be receiving the spell that turn you into your witchsona at mid ‚Ä¶ {'neg': 0.111, 'neu': 0.889, 'pos': 0.0, 'compound': -0.3612}\n",
      "cgtn on the scene around 15000 troop 32 equipment unit and 12 air formation composed of over 160 aircraft a ‚Ä¶ {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "looking like it may be a falllike weekend coming up dry cold front look to move through the area friday with hig ‚Ä¶ {'neg': 0.0, 'neu': 0.898, 'pos': 0.102, 'compound': 0.3612}\n",
      "i stopped caring what nigga think when i realized they will believe anything the next nigga tell them {'neg': 0.09, 'neu': 0.758, 'pos': 0.152, 'compound': 0.3182}\n",
      "live chaos expected on oct 1 across hong kong a antigovernment protester aim to spoil china partyl follow o ‚Ä¶ {'neg': 0.163, 'neu': 0.837, 'pos': 0.0, 'compound': -0.5719}\n",
      "i hold kievstheworld personally responsible for what just happened raw {'neg': 0.0, 'neu': 0.796, 'pos': 0.204, 'compound': 0.3182}\n",
      "fuckitripped exactly--------------------------------------------- {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "for text in texts_cleaned: \n",
    "    \n",
    "    score = analyzer.polarity_scores(text)\n",
    "    \n",
    "    print(\"{:-<65} {}\".format(text, str(score)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13c175b2",
   "metadata": {},
   "source": [
    "It seems like VADER can deal with all of the raw data without pre-processing and is therefore very robust to unprocessed data. Furthermore, VADER seems to be doing fine (only errors for NaN's) and makes useful outputs which make sense even though no pre-processing was applied in our raw data.\n",
    "\n",
    "Additionally, VADER has the advantage to make use of emoticons, UTF-8 encoded emojis, word-shapes, slangs, punctuations and inialisms/acronyms which surely helps to determine the overall sentiment more precisely. Therefore, these text types should not be removed in the pre-processing step. \n",
    "\n",
    "\n",
    "##### Example 1:\n",
    "\n",
    "###### Raw data:\n",
    "\n",
    "\"i stopped caring what niggas think when i realized they will believe anything the next nigga tell them.\" {'neg': 0.191, 'neu': 0.667, 'pos': 0.142, 'compound': -0.0258} \n",
    "\n",
    "###### Preproccessed: \n",
    "\n",
    "\"i stopped caring what nigga think when i realized they will believe anything the next nigga tell them\" {'neg': 0.09, 'neu': 0.758, 'pos': 0.152, 'compound': 0.3182}\n",
    "\n",
    "##### Example 2:\n",
    "\n",
    "###### Raw Data:\n",
    "\n",
    "I hold @kie_vs_theworld personally responsible for what just happened ü§∑üèæ‚Äç‚ôÇÔ∏èüòÇ #RAW {'neg': 0.07, 'neu': 0.704, 'pos': 0.226, 'compound': 0.6369}\n",
    "\n",
    "###### Preprocessed:\n",
    "\n",
    "i hold kievstheworld personally responsible for what just happened raw {'neg': 0.0, 'neu': 0.796, 'pos': 0.204, 'compound': 0.3182}\n",
    "\n",
    "##### Conclusion:\n",
    "\n",
    "As one can see at our example, it seems like our pre-processing introduce bias in terms of that surely negative contexts get biased in a direction of neutral or even positive connotation. Therefore, I would suggest to not pre-process the data using when using VADER due to the fact that the already implemented pre-processing techniques using the package are enough to reliably evaluate the provided social media data/ Twitter texts. \n",
    "\n",
    "As a result our implemented pre-processing functions like lemmatizaton, removal of NaN's, URLs, emojis, punctuations, tokenizations are not necessary anymore, since VADER already takes care of of these problems and many more, like the categorizations of mis-spellings as neutral or the incorporation of abbreviations to be able to categorize them (eg.:\"LOL\"). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b345f88",
   "metadata": {},
   "source": [
    "###### Q3: Apply this method to our TweetsCOV19 dataset and comment on the performance obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77d76904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'TweetId', 'Username', 'Timestamp', 'NoFollowers',\n",
       "       'NoFriends', 'NoRetweets', 'NoFavorites', 'Entities', 'Sentiment',\n",
       "       'Mentions', 'Hashtags', 'URLs', 'TweetText', 'UserLocation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd9d298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2 -1\n",
       "1    2 -1\n",
       "2    2 -3\n",
       "3    1 -1\n",
       "4    1 -1\n",
       "5    2 -1\n",
       "6    3 -1\n",
       "7    1 -1\n",
       "8    1 -1\n",
       "9    1 -1\n",
       "Name: Sentiment, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['Sentiment'].head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52866e89",
   "metadata": {},
   "source": [
    "Sentiment is the label of our Dataframe, it has a positive score and a negative score for the provided Tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "765b6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_texts = raw_data['TweetText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be83bc0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m compound_score\u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m complete_texts: \n\u001b[0;32m----> 3\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     compound_score\u001b[38;5;241m.\u001b[39mappend(score[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/vaderSentiment/vaderSentiment.py:241\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.polarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    239\u001b[0m text_no_emoji \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m prev_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mchr\u001b[39m \u001b[38;5;129;01min\u001b[39;00m text:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mchr\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memojis:\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# get the textual description\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memojis[\u001b[38;5;28mchr\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "compound_score= []\n",
    "for text in complete_texts: \n",
    "    score = analyzer.polarity_scores(text)\n",
    "    compound_score.append(score['compound'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a68c8569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         https://t.co/YSpREbX5VD\n",
       "TweetId         coast to coast & then some\n",
       "Username                               NaN\n",
       "Timestamp                              NaN\n",
       "NoFollowers                            NaN\n",
       "NoFriends                              NaN\n",
       "NoRetweets                             NaN\n",
       "NoFavorites                            NaN\n",
       "Entities                               NaN\n",
       "Sentiment                              NaN\n",
       "Mentions                               NaN\n",
       "Hashtags                               NaN\n",
       "URLs                                   NaN\n",
       "TweetText                              NaN\n",
       "UserLocation                           NaN\n",
       "Name: 641055, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.loc[641055,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ef348e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>Username</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>NoFollowers</th>\n",
       "      <th>NoFriends</th>\n",
       "      <th>NoRetweets</th>\n",
       "      <th>NoFavorites</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>URLs</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>UserLocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>641055</th>\n",
       "      <td>https://t.co/YSpREbX5VD</td>\n",
       "      <td>coast to coast &amp; then some</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644251</th>\n",
       "      <td>delay the testing and tracing of Jamaat attend...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644252</th>\n",
       "      <td>bank politics? #AarNoiMamata #‡¶Ü‡¶∞‡¶®‡¶Ø‡¶º‡¶Æ‡¶Æ‡¶§‡¶æ https:...</td>\n",
       "      <td>Kolkata, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651840</th>\n",
       "      <td>Now the problem is solved. https://t.co/67sMxS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663640</th>\n",
       "      <td>Now the problem is solved. https://t.co/67sMxS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Unnamed: 0  \\\n",
       "641055                            https://t.co/YSpREbX5VD   \n",
       "644251  delay the testing and tracing of Jamaat attend...   \n",
       "644252  bank politics? #AarNoiMamata #‡¶Ü‡¶∞‡¶®‡¶Ø‡¶º‡¶Æ‡¶Æ‡¶§‡¶æ https:...   \n",
       "651840  Now the problem is solved. https://t.co/67sMxS...   \n",
       "663640  Now the problem is solved. https://t.co/67sMxS...   \n",
       "\n",
       "                           TweetId Username Timestamp  NoFollowers  NoFriends  \\\n",
       "641055  coast to coast & then some      NaN       NaN          NaN        NaN   \n",
       "644251                         NaN      NaN       NaN          NaN        NaN   \n",
       "644252              Kolkata, India      NaN       NaN          NaN        NaN   \n",
       "651840                         NaN      NaN       NaN          NaN        NaN   \n",
       "663640                         NaN      NaN       NaN          NaN        NaN   \n",
       "\n",
       "        NoRetweets  NoFavorites Entities Sentiment Mentions Hashtags URLs  \\\n",
       "641055         NaN          NaN      NaN       NaN      NaN      NaN  NaN   \n",
       "644251         NaN          NaN      NaN       NaN      NaN      NaN  NaN   \n",
       "644252         NaN          NaN      NaN       NaN      NaN      NaN  NaN   \n",
       "651840         NaN          NaN      NaN       NaN      NaN      NaN  NaN   \n",
       "663640         NaN          NaN      NaN       NaN      NaN      NaN  NaN   \n",
       "\n",
       "       TweetText UserLocation  \n",
       "641055       NaN          NaN  \n",
       "644251       NaN          NaN  \n",
       "644252       NaN          NaN  \n",
       "651840       NaN          NaN  \n",
       "663640       NaN          NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[raw_data['TweetText'].isna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0939a9b9",
   "metadata": {},
   "source": [
    "###### Conclusion \n",
    "\n",
    "Need to convert all NaN values in column 'TweetText' because VADER can not deal with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9eef8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of NaN's\n",
    "new_data = raw_data[raw_data['TweetText'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef65e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retry VADER \n",
    "\n",
    "complete_texts= new_data['TweetText']\n",
    "compound_score= []\n",
    "\n",
    "for text in complete_texts: \n",
    "    score = analyzer.polarity_scores(text)\n",
    "    compound_score.append(score['compound'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48267117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentPredict(sentiment):\n",
    "    \n",
    "    for i in range(len(sentiment)):\n",
    "        \n",
    "        if sentiment[i] >= 0.05:\n",
    "             sentiment[i]= 1         #\"Positive\"\n",
    "    \n",
    "        elif sentiment[i] <= -0.05: \n",
    "             sentiment[i]=-1         #\"Negative\"\n",
    "    \n",
    "        else:\n",
    "             sentiment[i]=0          #\"Neutral\"\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfee6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_predict = sentimentPredict(compound_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53c8164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sentiment= new_data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b763b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert str from tweet_sentiment to integer values \n",
    "tweet_sentiment_int=[]\n",
    "\n",
    "for s in tweet_sentiment:\n",
    "    a, b = map(int, s.split())\n",
    "    c=[a,b]\n",
    "    tweet_sentiment_int.append(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcf9b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sentiment_sum=[]\n",
    "for number in tweet_sentiment_int:\n",
    "    summed= sum(number)\n",
    "    tweet_sentiment_sum.append(summed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96f91701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_int_to_sentiment(sentiment):\n",
    "    for i in range(len(sentiment)):\n",
    "        \n",
    "        if sentiment[i] >0:\n",
    "             sentiment[i]= 1    #\"Positive\"\n",
    "    \n",
    "        elif sentiment[i] < 0: \n",
    "             sentiment[i]=-1    #\"Negative\"\n",
    "    \n",
    "        else:\n",
    "             sentiment[i]=0     #\"Neutral\"\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5f8eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sentiment= convert_int_to_sentiment(tweet_sentiment_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b006697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e4bf17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5740915423089935\n"
     ]
    }
   ],
   "source": [
    "score= balanced_accuracy_score(tweet_sentiment, sentiment_predict, adjusted=False)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8fd1517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36113731346349026\n"
     ]
    }
   ],
   "source": [
    "score_adjusted = balanced_accuracy_score(tweet_sentiment, sentiment_predict, adjusted=True)\n",
    "print(score_adjusted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ce380cb",
   "metadata": {},
   "source": [
    "In our evalutation of the performance of the VADER package we used the outputted compound score of the package which predicts the overall sentiment of the Tweet. As comparison, we used the labels of our dataset and summed both the positive and negative labels per Tweet to get an overall sentiment score for each Tweet.\n",
    "\n",
    "\n",
    "\n",
    "Moreover, we will use the adjusted balanced accuracy score as a metric to evaluate the performance of the package. The adjusted balanced accuracy score is a metric that is used to evaluate the performance of a classifier. It is a balanced accuracy score that is adjusted for chance. \n",
    "\n",
    "As a small remark, using the adjusted balanced accuracy score, a score of 1 would mean a perfect performance, while a adjusted score of 0 would mean random guessing. Therefore, with an adjusted balance accuracy score of 0.36 VADER seems to be better than random in classifying the sentiment of twitter texts but there is still a lot of potential to be better. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e78661bf",
   "metadata": {},
   "source": [
    "##### Conclusion of Q3\n",
    "\n",
    "As a result, one can say that VADER is a quite good start for classifying sentiments of twitter texts but as one can see it is far away of being a perfect classifier. Reflecting on our applied methods, we used heuristics such as taking the sum of the positive and negative score from the sentiment labels in the TweetsCOV19 dataset and for example interpreted a positive sum as a positive sentiment statement. Furthermore, we applied thresholds described on the VADER GitHub page for the compound scores which helped categorizing compound scores into positive, neutral or negative predictions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
