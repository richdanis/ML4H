{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIElnLXBcfqv",
        "outputId": "c104b2b7-eecc-41de-8756-eb524dfc800d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "# mount drive to access data\n",
        "drive.mount('/content/drive')\n",
        "# load data folder into working directory\n",
        "!cp -r drive/MyDrive/data .\n",
        "!cp -r drive/MyDrive/preprocessing.py ."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ErPTyWiuceLh"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q8QoiDmceLi"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import re\n",
        "import preprocessing as p\n",
        "from nltk.util import bigrams\n",
        "from itertools import compress\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zRviqM0ceLl",
        "outputId": "b0cd05a5-9810-476e-be19-44b2c22e78b0"
      },
      "outputs": [],
      "source": [
        "# loading raw data\n",
        "raw_data = pd.read_csv('data/TweetsCOV19.csv')\n",
        "# loading data with preprocessed tweets\n",
        "data = pd.read_csv('data/cleaned_tweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xYDFWFckceLs"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# tokenize the preprocessed tweets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tweets \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mTweetText\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m----> 3\u001b[0m tokenized_tweets \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mtokenization(tweets)\n",
            "File \u001b[0;32m~/MSc/Sem2/3_Machine_Learning_for_Health_Care/ML4H/Project 2/preprocessing.py:82\u001b[0m, in \u001b[0;36mtokenization\u001b[0;34m(tweets)\u001b[0m\n\u001b[1;32m     79\u001b[0m tokenizer \u001b[39m=\u001b[39m TweetTokenizer(preserve_case\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, strip_handles\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_len\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     81\u001b[0m \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m tweets:\n\u001b[0;32m---> 82\u001b[0m     tokenized_tweets\u001b[39m.\u001b[39mappend(tokenizer\u001b[39m.\u001b[39;49mtokenize(tweet))\n\u001b[1;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m tokenized_tweets\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/ML4H/lib/python3.9/site-packages/nltk/tokenize/casual.py:380\u001b[0m, in \u001b[0;36mTweetTokenizer.tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39m# Recognise phone numbers during tokenization\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatch_phone_numbers:\n\u001b[0;32m--> 380\u001b[0m     words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mPHONE_WORD_RE\u001b[39m.\u001b[39;49mfindall(safe_text)\n\u001b[1;32m    381\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWORD_RE\u001b[39m.\u001b[39mfindall(safe_text)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# tokenize the preprocessed tweets\n",
        "tweets = data['TweetText'].tolist()\n",
        "tokenized_tweets = p.tokenization(tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9r6A0JHfceLt"
      },
      "outputs": [],
      "source": [
        "# returns ngrams, ordered by frequency\n",
        "def ngram_freq(tweets, n):\n",
        "\n",
        "    ngrams = dict()\n",
        "\n",
        "    for tweet in tweets:\n",
        "        for i in range(len(tweet)-n + 1):\n",
        "            if tuple(tweet[i:i+n]) in ngrams:\n",
        "                ngrams[tuple(tweet[i:i+n])] += 1\n",
        "            else:\n",
        "                ngrams[tuple(tweet[i:i+n])] = 1\n",
        "\n",
        "    ngrams = sorted(ngrams.items(), key=lambda x:-x[1])\n",
        "\n",
        "    return ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sKfQkWDceLu"
      },
      "outputs": [],
      "source": [
        "# remove nans from raw_data\n",
        "raw_data = raw_data[raw_data['TweetText'].notnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9PbeDrTceLv"
      },
      "outputs": [],
      "source": [
        "# turn tweets into words\n",
        "raw_tweets = raw_data['TweetText'].tolist()\n",
        "for i, tweet in enumerate(raw_tweets):\n",
        "  raw_tweets[i] = tweet.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmrh_aZsceLv"
      },
      "outputs": [],
      "source": [
        "# get most frequent unigrams and bigrams\n",
        "unigrams = ngram_freq(tokenized_tweets, 1)\n",
        "raw_unigrams = ngram_freq(raw_tweets, 1)\n",
        "bigrams = ngram_freq(tokenized_tweets, 2)\n",
        "raw_bigrams = ngram_freq(raw_tweets, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "U32IxFokceL0",
        "outputId": "8c9bdeb5-fd35-4c39-dab9-c820399f50b5"
      },
      "outputs": [],
      "source": [
        "# plot unigram, bigram frequency before and after preprocessing \n",
        "fig, ax = plt.subplots(2, 2, sharey='row', figsize=(10,8))\n",
        "\n",
        "titles = ['Most common unigrams before preprocessing', \\\n",
        "          'Most common unigrams after preprocessing', \\\n",
        "          'Most common bigrams before preprocessing', \\\n",
        "          'Most common bigrams after preprocessing']\n",
        "grams = [raw_unigrams, unigrams, raw_bigrams, bigrams]\n",
        "pos = [i for i in range(10)] # position of bars\n",
        "\n",
        "for i, (title, gram) in enumerate(zip(titles, grams)):\n",
        "\n",
        "    words = [gram[j][0][0] for j in range(10)]\n",
        "    if i > 1:\n",
        "        words = [' '.join(gram[j][0]) for j in range(10)]\n",
        "    freq = [gram[j][1] for j in range(10)]\n",
        "\n",
        "    ax[i//2][i % 2].bar(pos, freq, align='center', color='b', alpha=0.6)\n",
        "    ax[i//2][i % 2].set_xticks(pos)\n",
        "    ax[i//2][i % 2].set_xticklabels(words, fontsize=12, rotation='vertical')\n",
        "    ax[i//2][i % 2].set_title(title, fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"uni-bigram-frequencies.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6T5YqE7ceL1"
      },
      "outputs": [],
      "source": [
        "# get sentiment frequencies\n",
        "def sentiment_freq(data):\n",
        "\n",
        "  sentiments = data['Sentiment'].tolist()\n",
        "  freqs = dict()\n",
        "  for s in sentiments:\n",
        "    p, n = s.split()\n",
        "    p = int(p)\n",
        "    n = int(n)\n",
        "    if p in freqs:\n",
        "      freqs[p] += 1\n",
        "    else:\n",
        "      freqs[p] = 1\n",
        "    if n in freqs:\n",
        "      freqs[n] += 1\n",
        "    else:\n",
        "      freqs[n] = 1\n",
        "\n",
        "  # turn dictionary into list\n",
        "  sentlist = list(freqs.items())\n",
        "\n",
        "  # order by sentiment for plot\n",
        "  sentlist.sort(key=lambda x: x[0])\n",
        "\n",
        "  return sentlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "fmweb6oV9gB-",
        "outputId": "b9cb6e62-f8a3-422c-822c-8ebe55a84861"
      },
      "outputs": [],
      "source": [
        "sentlist = sentiment_freq(data)\n",
        "sentiment = [str(x[0]) for x in sentlist]\n",
        "sent_freq = pd.Series([x[1] for x in sentlist])\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "ax = sent_freq.plot(kind=\"bar\", width=0.7, color='b', alpha=0.6)\n",
        "ax.set_title(\"Sentiment Frequencies\")\n",
        "ax.set_xlabel(\"Sentiment\")\n",
        "ax.set_ylabel(\"Frequency\")\n",
        "ax.set_xticklabels(sentiment)\n",
        "\n",
        "rects = ax.patches\n",
        "labels = [str(x[1]) for x in sentlist]\n",
        "\n",
        "for rect, label in zip(rects, labels):\n",
        "    height = rect.get_height()\n",
        "    ax.text(\n",
        "        rect.get_x() + rect.get_width() / 2, height + 5, label, ha=\"center\", \\\n",
        "         va=\"bottom\"\n",
        "    )\n",
        "plt.savefig(\"sentiment-distribution.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cz95tYeeo9Cq"
      },
      "outputs": [],
      "source": [
        "def sentiment_word_count_distribution(data):\n",
        "\n",
        "  sentiments = data['Sentiment'].tolist()\n",
        "  # split into positive and negative sentiments\n",
        "  positive = []\n",
        "  negative = []\n",
        "\n",
        "  for s in sentiments:\n",
        "    p, n = s.split()\n",
        "    p = int(p)\n",
        "    n = int(n)\n",
        "    positive.append(p)\n",
        "    negative.append(n)\n",
        "\n",
        "  # select very positive, very negative and neutral sentiments\n",
        "  pos_five = [x == 5 or x == 4 for x in positive]\n",
        "  neg_five = [x == -5 or x == -4 for x in negative]\n",
        "  neutral = [x == 1 and y == -1 for x,y in zip(positive, negative)]\n",
        "\n",
        "  positive_tweets = list(compress(tokenized_tweets, pos_five))\n",
        "  negative_tweets = list(compress(tokenized_tweets, neg_five))\n",
        "  neutral_tweets = list(compress(tokenized_tweets, neutral))\n",
        "\n",
        "  count_positive = [len(x) for x in positive_tweets]\n",
        "  count_negative = [len(x) for x in negative_tweets]\n",
        "  count_neutral = [len(x) for x in neutral_tweets]\n",
        "\n",
        "  # normalize in range 1 to 0\n",
        "\n",
        "  return [count_negative, count_neutral, count_positive]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ryb6dV6BuyF3"
      },
      "outputs": [],
      "source": [
        "counts = sentiment_word_count_distribution(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mas5R_GRu427"
      },
      "outputs": [],
      "source": [
        "def plot_wordcount_histogram(ax, counts, title):\n",
        "\n",
        "  d = np.diff(np.unique(counts)).min()\n",
        "  left_of_first_bin = min(counts) - float(d)/2\n",
        "  right_of_last_bin = max(counts) + float(d)/2\n",
        "  ax.hist(counts, np.arange(left_of_first_bin, right_of_last_bin + d, d),\\\n",
        "          density=True, color='b', alpha=0.6)\n",
        "  ax.set_title(title, fontsize=10)\n",
        "  ax.set_xlabel(\"Word count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "aHsmzz0fOajS",
        "outputId": "ee2d3b4d-e715-4569-94d8-f9a06395d710"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 3, sharey='row', figsize=(12,4))\n",
        "titles = [\"Negative (-4, -5)\", \"Neutral (-1, +1)\", \"Positive (+4, +5)\"]\n",
        "for axis, count, title in zip(ax, counts, titles):\n",
        "  plot_wordcount_histogram(axis, count, title)\n",
        "fig.suptitle(\"Word count density as a function of sentiment\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"wordcount-densities.png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pytcu10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
